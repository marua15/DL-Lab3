{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://alkhalilarabic.com/\n",
      "Text:\n",
      "الخليل لتعليم اللغة العربية اكتسب المهارات اللغوية وتعرف على الثقافة العربية لتفتح عالمك مع منصة الخليل. تعلم العربية في دورات عن بعد على أيدي خبراء انطلق في تعلم العربية وصقل مهاراتك اللغوية في القراءة والكتابة والمحادثة والاستماع من خلال الدورات الأساسية على منصة الخليل تعلم اللغة العربية من الخبراء في اللغة الناطقين بالعربية، وانغمس في ثقافتها، وتعرف على قيمها وحضارتها. تعلم اللغة العربية باحترافية وطوّر مهاراتك اللغوية عبر منصتنا التعليمية المتطورة وأنت في أي موقع من العالم. بإمكانك ممارسة وتطوير مهارة المحادثة لساعات إضافية مع أفضل المدرسين العرب، وفي الأوقات التي تناسبك. اكتسب مهارات لغوية جديدة ترتبط بمجال عملك أو دراستك أو اهتمامك اللغوي في المجالات الدبلوماسية أو الإعلامية أو الأكاديمية أو غيرها أحد مشاريع شركة مؤتلف (إبانة)\n",
      "Score: 0.743\n",
      "\n",
      "URL: https://guidetoarabic.net/ar\n",
      "Text:\n",
      "اللغة العربية هي لغة القرآن الكريم، وهي وسيلة لفهم النصوص الشرعية، والاستنباط الصحيح من النصوص، وتعلم اللغة العربية واجب على المسلمين لفهم القرآن الكريم والسنة النبوية، ولا بد من دراسة العلوم المرتبطة باللغة العربية مثل: علم النحو والبلاغة، والقواعد والإعراب، وعلم البيان والأدب. هنا نحدثك عن فضل العربية ومكانتها بين اللغات وما فيها من دلائل الإعجاز، وعن منزلتها من الإسلام وعن الأسباب التي تدعوك لتعلمها وتعليمها. مواد متنوعة تبحث في كيفية تعلم اللغة العربية، والطُّرق المُثلَى لتعليمها، والمناهج المتَّبعة في هذا المجال، مع إضاءات على بعض المشكلات اللغوية وطرق معالجتها. نوفِّر لك في هذا القسم قاعدة بياناتٍ كبيرةً تحوي بيانات وعناوين الجامعات والأكاديميات ومعاهد ومراكز تعليم اللغة العربية في العالم، لكي يتمكَّن الجميع من البحث عن أقرب المراكز التعليمية إليهم، والتواصل معها مباشرة، من خلال الخارطة الرقمية التي تظهر في أعلى القسم.    هنا نحدثك عن فضل العربية ومكانتها بين اللغات وما فيها من دلائل الإعجاز، وعن منزلتها من الإسلام وعن الأسباب التي تدعوك لتعلمها وتعليمها.  مواد متنوعة تبحث في كيفية تعلم اللغة العربية، والطُّرق المُثلَى لتعليمها، والمناهج المتَّبعة في هذا المجال، مع إضاءات على بعض المشكلات اللغوية وطرق معالجتها.     نوفِّر لك في هذا القسم قاعدة بياناتٍ كبيرةً تحوي بيانات وعناوين الجامعات والأكاديميات ومعاهد ومراكز تعليم اللغة العربية في العالم، لكي يتمكَّن الجميع من البحث عن أقرب المراكز التعليمية إليهم،   دليل إلكترونيّ جامع لخدمات تعليم العربية للناطقين بغيرها، وما يتعلق بها من مبادرات ومشاريع وأفكار، يقدم للعاملين في هذا الحقل ما يعينهم على ترشيد أعمالهم، والوقوف على مواطن الاحتياج والنقص،    الدليل إلى العربية أحد مبادرات مركز أصول\n",
      "Score: 1.566\n",
      "\n",
      "['الخليل لتعليم اللغة العربية اكتسب المهارات اللغوية وتعرف على الثقافة العربية لتفتح عالمك مع منصة الخليل. تعلم العربية في دورات عن بعد على أيدي خبراء انطلق في تعلم العربية وصقل مهاراتك اللغوية في القراءة والكتابة والمحادثة والاستماع من خلال الدورات الأساسية على منصة الخليل تعلم اللغة العربية من الخبراء في اللغة الناطقين بالعربية، وانغمس في ثقافتها، وتعرف على قيمها وحضارتها. تعلم اللغة العربية باحترافية وطوّر مهاراتك اللغوية عبر منصتنا التعليمية المتطورة وأنت في أي موقع من العالم. بإمكانك ممارسة وتطوير مهارة المحادثة لساعات إضافية مع أفضل المدرسين العرب، وفي الأوقات التي تناسبك. اكتسب مهارات لغوية جديدة ترتبط بمجال عملك أو دراستك أو اهتمامك اللغوي في المجالات الدبلوماسية أو الإعلامية أو الأكاديمية أو غيرها أحد مشاريع شركة مؤتلف (إبانة)', 'اللغة العربية هي لغة القرآن الكريم، وهي وسيلة لفهم النصوص الشرعية، والاستنباط الصحيح من النصوص، وتعلم اللغة العربية واجب على المسلمين لفهم القرآن الكريم والسنة النبوية، ولا بد من دراسة العلوم المرتبطة باللغة العربية مثل: علم النحو والبلاغة، والقواعد والإعراب، وعلم البيان والأدب. هنا نحدثك عن فضل العربية ومكانتها بين اللغات وما فيها من دلائل الإعجاز، وعن منزلتها من الإسلام وعن الأسباب التي تدعوك لتعلمها وتعليمها. مواد متنوعة تبحث في كيفية تعلم اللغة العربية، والطُّرق المُثلَى لتعليمها، والمناهج المتَّبعة في هذا المجال، مع إضاءات على بعض المشكلات اللغوية وطرق معالجتها. نوفِّر لك في هذا القسم قاعدة بياناتٍ كبيرةً تحوي بيانات وعناوين الجامعات والأكاديميات ومعاهد ومراكز تعليم اللغة العربية في العالم، لكي يتمكَّن الجميع من البحث عن أقرب المراكز التعليمية إليهم، والتواصل معها مباشرة، من خلال الخارطة الرقمية التي تظهر في أعلى القسم.    هنا نحدثك عن فضل العربية ومكانتها بين اللغات وما فيها من دلائل الإعجاز، وعن منزلتها من الإسلام وعن الأسباب التي تدعوك لتعلمها وتعليمها.  مواد متنوعة تبحث في كيفية تعلم اللغة العربية، والطُّرق المُثلَى لتعليمها، والمناهج المتَّبعة في هذا المجال، مع إضاءات على بعض المشكلات اللغوية وطرق معالجتها.     نوفِّر لك في هذا القسم قاعدة بياناتٍ كبيرةً تحوي بيانات وعناوين الجامعات والأكاديميات ومعاهد ومراكز تعليم اللغة العربية في العالم، لكي يتمكَّن الجميع من البحث عن أقرب المراكز التعليمية إليهم،   دليل إلكترونيّ جامع لخدمات تعليم العربية للناطقين بغيرها، وما يتعلق بها من مبادرات ومشاريع وأفكار، يقدم للعاملين في هذا الحقل ما يعينهم على ترشيد أعمالهم، والوقوف على مواطن الاحتياج والنقص،    الدليل إلى العربية أحد مبادرات مركز أصول']\n",
      "[0.743, 1.566]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to scrape text from a website\n",
    "def scrape_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Modify this based on the structure of the webpage to extract relevant text\n",
    "    text = ' '.join([p.text for p in soup.find_all('p')])\n",
    "    return text\n",
    "\n",
    "# Define URLs of Arabic websites related to your topic\n",
    "urls = [\n",
    "    'https://alkhalilarabic.com/',\n",
    "    'https://guidetoarabic.net/ar'\n",
    "]\n",
    "\n",
    "# Define a function to calculate text score based on some criteria\n",
    "def calculate_text_score(text):\n",
    "    return len(text) / 1000  # Just a simple scaling factor for demonstration\n",
    "\n",
    "# Create a dictionary to store text and corresponding scores\n",
    "data = {}\n",
    "texts =[]\n",
    "scores =[]\n",
    "\n",
    "# Scrape text from each URL and calculate the score\n",
    "for url in urls:\n",
    "    text = scrape_text(url)\n",
    "    texts.append(text)\n",
    "    score = calculate_text_score(text)\n",
    "    scores.append(score)\n",
    "    data[url] = {'text': text, 'score': score}\n",
    "\n",
    "# Print the data\n",
    "for url, info in data.items():\n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Text:\\n{info['text']}\")\n",
    "    print(f\"Score: {info['score']}\\n\")\n",
    "    \n",
    "print(texts)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'text_data' contains our preprocessed text data\n",
    "texts = [info['text'] for info in data.values()]\n",
    "scores = [info['score'] for info in data.values()]\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Padding sequences to ensure uniform length\n",
    "max_len = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# Converting scores to numpy array\n",
    "labels = np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0610 - mae: 0.2471 - val_loss: 1.1195 - val_mae: 1.0581\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0569 - mae: 0.2384 - val_loss: 1.1138 - val_mae: 1.0554\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0528 - mae: 0.2298 - val_loss: 1.1077 - val_mae: 1.0525\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0488 - mae: 0.2208 - val_loss: 1.1010 - val_mae: 1.0493\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0445 - mae: 0.2110 - val_loss: 1.0933 - val_mae: 1.0456\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0400 - mae: 0.2000 - val_loss: 1.0845 - val_mae: 1.0414\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0351 - mae: 0.1874 - val_loss: 1.0740 - val_mae: 1.0364\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0298 - mae: 0.1726 - val_loss: 1.0616 - val_mae: 1.0303\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0240 - mae: 0.1548 - val_loss: 1.0463 - val_mae: 1.0229\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0177 - mae: 0.1331 - val_loss: 1.0269 - val_mae: 1.0134\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0599 - mae: 0.2448 - val_loss: 1.1223 - val_mae: 1.0594\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0521 - mae: 0.2282 - val_loss: 1.1143 - val_mae: 1.0556\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0449 - mae: 0.2118 - val_loss: 1.1060 - val_mae: 1.0516\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0380 - mae: 0.1951 - val_loss: 1.0970 - val_mae: 1.0474\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0314 - mae: 0.1772 - val_loss: 1.0872 - val_mae: 1.0427\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0249 - mae: 0.1576 - val_loss: 1.0762 - val_mae: 1.0374\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0184 - mae: 0.1357 - val_loss: 1.0635 - val_mae: 1.0313\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0122 - mae: 0.1106 - val_loss: 1.0488 - val_mae: 1.0241\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0066 - mae: 0.0814 - val_loss: 1.0313 - val_mae: 1.0155\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0022 - mae: 0.0473 - val_loss: 1.0106 - val_mae: 1.0053\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0560 - mae: 0.2367 - val_loss: 1.1356 - val_mae: 1.0657\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0512 - mae: 0.2262 - val_loss: 1.1282 - val_mae: 1.0622\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0465 - mae: 0.2156 - val_loss: 1.1206 - val_mae: 1.0586\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0420 - mae: 0.2048 - val_loss: 1.1126 - val_mae: 1.0548\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0375 - mae: 0.1937 - val_loss: 1.1042 - val_mae: 1.0508\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0331 - mae: 0.1820 - val_loss: 1.0952 - val_mae: 1.0465\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0288 - mae: 0.1698 - val_loss: 1.0856 - val_mae: 1.0419\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0246 - mae: 0.1568 - val_loss: 1.0753 - val_mae: 1.0370\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0205 - mae: 0.1431 - val_loss: 1.0641 - val_mae: 1.0316\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0165 - mae: 0.1285 - val_loss: 1.0521 - val_mae: 1.0257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29b8d7164d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# RNN Model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len))\n",
    "rnn_model.add(LSTM(64))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "rnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "rnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Bidirectional RNN Model\n",
    "bidirectional_rnn_model = Sequential()\n",
    "bidirectional_rnn_model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len))\n",
    "bidirectional_rnn_model.add(Bidirectional(LSTM(64)))\n",
    "bidirectional_rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "bidirectional_rnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "bidirectional_rnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# GRU Model\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len))\n",
    "gru_model.add(GRU(64))\n",
    "gru_model.add(Dense(1, activation='sigmoid'))\n",
    "gru_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "gru_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0269 - mae: 1.0134\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0106 - mae: 1.0053\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0521 - mae: 1.0257\n",
      "RNN Model Evaluation:\n",
      "Mean Squared Error: 1.0269255638122559\n",
      "Mean Absolute Error: 1.0133733749389648\n",
      "\n",
      "Bidirectional RNN Model Evaluation:\n",
      "Mean Squared Error: 1.0106168985366821\n",
      "Mean Absolute Error: 1.0052944421768188\n",
      "\n",
      "GRU Model Evaluation:\n",
      "Mean Squared Error: 1.052139163017273\n",
      "Mean Absolute Error: 1.0257383584976196\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "rnn_scores = rnn_model.evaluate(X_test, y_test)\n",
    "bidirectional_rnn_scores = bidirectional_rnn_model.evaluate(X_test, y_test)\n",
    "gru_scores = gru_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"RNN Model Evaluation:\")\n",
    "print(\"Mean Squared Error:\", rnn_scores[0])\n",
    "print(\"Mean Absolute Error:\", rnn_scores[1])\n",
    "\n",
    "print(\"\\nBidirectional RNN Model Evaluation:\")\n",
    "print(\"Mean Squared Error:\", bidirectional_rnn_scores[0])\n",
    "print(\"Mean Absolute Error:\", bidirectional_rnn_scores[1])\n",
    "\n",
    "print(\"\\nGRU Model Evaluation:\")\n",
    "print(\"Mean Squared Error:\", gru_scores[0])\n",
    "print(\"Mean Absolute Error:\", gru_scores[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
